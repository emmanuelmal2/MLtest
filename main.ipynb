{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Se tiene acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos. Se tiene que  crear un modelo que escoja el plan correcto con la mayor exactitud posible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentacion de nuestros datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando las librerias necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "print(df.info())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiendo mi conjunto de datos \n",
    "# 20% a test \n",
    "df_temp, df_test = train_test_split(df, test_size = 0.20, random_state = 54321) \n",
    "# 60% a train y %20 a valid porque el 25% de 80% es 20%\n",
    "df_train, df_valid = train_test_split(df_temp, test_size = 0.25, random_state = 54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos para entrenamiento \n",
    "features_train = df_train.drop(['is_ultra'], axis = 1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# Datos para validacion\n",
    "features_valid = df_valid.drop(['is_ultra'], axis = 1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "# Datos para test\n",
    "features_test = df_test.drop(['is_ultra'], axis = 1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando la calidad de distintos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol de decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo en el conjunto de validación (n_estimators = 5): 0.8180404354587869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(random_state = 54321, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    acurracy_decisionTree = model.score(features_valid, target_valid)\n",
    "    if acurracy_decisionTree > best_score:\n",
    "        best_score = acurracy_decisionTree\n",
    "        best_depth = depth\n",
    "print(\"La exactitud del modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_depth, best_score))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantizar que la evaluación en el conjunto de prueba refleje el rendimiento del modelo con el mejor hiperparámetro y aprovechando toda la información válida, se reentrena el modelo final justo antes de medir su exactitud en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo en el conjunto de test = 0.7698289269051322\n"
     ]
    }
   ],
   "source": [
    "# Entrenando el modelo nuevamente con los hiperparametros obtenidos\n",
    "modelDecisionTree = DecisionTreeClassifier(random_state = 54321, max_depth = best_depth)\n",
    "modelDecisionTree.fit(features_train, target_train)\n",
    "scoreDecisionTree =  modelDecisionTree.score(features_test, target_test)\n",
    "print(\"La exactitud del modelo en el conjunto de test = {}\".format(scoreDecisionTree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque aleatorio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 10): 0.8258164852255054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for estimator in range(1,11):\n",
    "    model = RandomForestClassifier(random_state = 54321, n_estimators = estimator)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    acurracy_randomForest = model.score(features_valid, target_valid)\n",
    "    if acurracy_randomForest > best_score:\n",
    "        best_score = acurracy_randomForest\n",
    "        best_est = estimator\n",
    "\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el caso del arbol de decisión se tiene que reentrenar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo en el conjunto de test = 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "# Entrenando el modelo nuevamente con lo obtenido\n",
    "modelForestClassifier = RandomForestClassifier(random_state = 54321, n_estimators = best_est)\n",
    "modelForestClassifier.fit(features_train, target_train)\n",
    "scoreRandomForest = modelForestClassifier.score(features_test, target_test)\n",
    "print(\"La exactitud del modelo en el conjunto de test = {}\".format(scoreRandomForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de regresión logística en el conjunto de test: 0.6780715396578538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "modelLogisticRegression = LogisticRegression(random_state=54321, solver = 'liblinear')\n",
    "modelLogisticRegression.fit(features_train, target_train)\n",
    "scorelRegression = modelLogisticRegression.score(features_test, target_test) # No usamos el conjunto de validación pues no estamos ajustando hiperparametros\n",
    "print(\"Accuracy del modelo de regresión logística en el conjunto de test:\", scorelRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de cordura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos realizar una prueba de cordura con un dataset que sabremos siempre su respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCordura = pd.DataFrame([\n",
    "  # Ningún uso\n",
    "  {'calls':  0,   'minutes':    0,   'messages':   0,   'mb_used':     0},\n",
    "  # Uso muy alto\n",
    "  {'calls':200, 'minutes': 2000, 'messages': 500, 'mb_used':100_000},\n",
    "  # Uso promedio \n",
    "  {'calls':20,  'minutes':  200,  'messages':  30,  'mb_used':  1000},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones arbol de decision: [0 1 0]\n",
      "Predicciones bosque aleatorio: [1 1 1]\n",
      "Predicciones regresión lógistica: [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "preds = modelDecisionTree.predict(datasetCordura)\n",
    "print(\"Predicciones arbol de decision:\", preds)\n",
    "preds = modelForestClassifier.predict(datasetCordura)\n",
    "print(\"Predicciones bosque aleatorio:\", preds)\n",
    "preds = modelLogisticRegression.predict(datasetCordura)\n",
    "print(\"Predicciones regresión lógistica:\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al evaluar los tres modelos sobre escenarios “obvios” observamos:\n",
    "\n",
    "- Árbol de decisión: predice [0, 1, 0], acertando en los dos extremos y ofreciendo un resultado coherente en el caso intermedio.\n",
    "\n",
    "- Bosque aleatorio: predice [1, 1, 1], recomendando Ultra en todos los casos, lo cual no tiene sentido para el usuario sin consumo (primer caso).\n",
    "\n",
    "- Regresión logística: predice [0, 0, 1], falla en el extremo (debería sugerir Ultra) y muestra un comportamiento menos consistente.\n",
    "\n",
    "Por tanto, solo el árbol de decisión pasa completamente la prueba de cordura, reaccionando de forma intuitiva a los escenarios definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eligiendo al mejor modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo con mayor precision es el bosque de decision con 0.7838258164852255 de precision\n"
     ]
    }
   ],
   "source": [
    "def bestModel(scoreDecisionTree, scoreRandomForest, scorelRegression):\n",
    "    if scoreDecisionTree > scoreRandomForest:\n",
    "        if scoreDecisionTree > scorelRegression:\n",
    "            return print(\"El modelo con mayor precision es el arbol de decision con {} de precision\".format(scoreDecisionTree))\n",
    "    if scoreRandomForest > scorelRegression:\n",
    "        return print(\"El modelo con mayor precision es el bosque de decision con {} de precision\".format(scoreRandomForest))\n",
    "    return print(\"El modelo con mayor precision es la regresión logística con {} de precision\".format(scorelRegression))\n",
    "\n",
    "bestModel(scoreDecisionTree, scoreRandomForest, scorelRegression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol de decisión, con un 76,98 % de exactitud en el conjunto de prueba y un comportamiento coherente en los escenarios de cordura, supera el umbral mínimo del 75 % exigido y demuestra una capacidad intuitiva para recomendar planes según el perfil de uso; aunque el bosque aleatorio logró una precisión ligeramente mayor (78,38 %), su tendencia a asignar Ultra en todos los casos triviales evidencia un sesgo que lo hace menos confiable para usuarios de bajo consumo, y la regresión logística quedó por debajo del umbral (67,81 %), por lo que el árbol de decisión resulta ser la opción óptima para la recomendación de planes Smart o Ultra en Megaline."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 299,
    "start_time": "2025-05-05T16:56:51.017Z"
   },
   {
    "duration": 483,
    "start_time": "2025-05-05T17:27:24.073Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
